{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(caption):\n",
    "    # Remove punctuation, numbers, and special characters, keeping only words\n",
    "    caption = re.sub(r'[^a-zA-Z\\s]', '', caption)\n",
    "    # Convert to lowercase\n",
    "    caption = caption.lower()\n",
    "    # Remove extra whitespace\n",
    "    caption = ' '.join(caption.split())\n",
    "    return caption\n",
    "\n",
    "def countWords(caption):\n",
    "    wordList = caption.split(' ')\n",
    "    return len(wordList)\n",
    "\n",
    "def characterCount(caption):\n",
    "    text = caption.replace(\" \", \"\")\n",
    "    characters = [char for char in text]\n",
    "    return len(characters)\n",
    "\n",
    "def sentenceCount(caption):\n",
    "    # Using regular expression to split the caption into sentences\n",
    "    sentences = re.split(r'[.!?]', caption)\n",
    "\n",
    "    sentences = [sentence for sentence in sentences if sentence.strip()]\n",
    "\n",
    "    return len(sentences)\n",
    "\n",
    "def calculateAvgWordLen(caption):\n",
    "    wordList = caption.split(' ')\n",
    "    totalLen = 0\n",
    "    for word in wordList:\n",
    "        totalLen += len(word)\n",
    "    \n",
    "    return totalLen/len(wordList)\n",
    "\n",
    "def calculateAvgSentLen(caption):\n",
    "    sentences = re.split(r'[.!?]', caption)\n",
    "    wps = 0\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():\n",
    "            words = sentence.split()\n",
    "            wps += len(words)\n",
    "    \n",
    "    return wps/len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_pos_tags(caption):\n",
    "    # Process the caption\n",
    "    doc = nlp(caption)\n",
    "\n",
    "    # Extract the POS tags\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "    return pos_tags\n",
    "\n",
    "def extract_named_entity(caption):\n",
    "    # Process the caption\n",
    "    doc = nlp(caption)\n",
    "\n",
    "    # Extract named entities\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    return entities\n",
    "\n",
    "def rearrangePosTags(captions):\n",
    "    tags = {}\n",
    "    for caption in captions:\n",
    "        for word, pos_tag in caption:\n",
    "            if pos_tag in tags:\n",
    "                tags[pos_tag] += 1\n",
    "            else:\n",
    "                tags[pos_tag] = 1\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def rearrangeNamedEntityTags(captions):\n",
    "    tags = {}\n",
    "    for caption in captions:\n",
    "        for name, entity in caption:\n",
    "            if entity in tags:\n",
    "                tags[entity] += 1\n",
    "            else:\n",
    "                tags[entity] = 1\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(captions):\n",
    "    scores = []\n",
    "    for caption in captions:\n",
    "        blob = TextBlob(caption)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        # Normalize sentiment score from range [-1, 1] to [0, 1]\n",
    "        normalized_sentiment = (sentiment + 1) / 2\n",
    "        scores.append(normalized_sentiment)\n",
    "    \n",
    "    normalized_score = np.mean(scores)\n",
    "    return normalized_score\n",
    "\n",
    "def calculate_subjectivity(caption):\n",
    "    blob = TextBlob(caption)\n",
    "    subjectivity_scores = blob.sentiment.subjectivity\n",
    "\n",
    "    return subjectivity_scores\n",
    "\n",
    "def calculate_readability_scores(captions):\n",
    "    readability_scores = []\n",
    "    for caption in captions:\n",
    "        reading_ease = textstat.flesch_reading_ease(caption)\n",
    "\n",
    "        # Ensure scores are within the 0-100 range\n",
    "        if reading_ease < 0:\n",
    "            reading_ease = 0\n",
    "        elif reading_ease > 100:\n",
    "            reading_ease = 100\n",
    "\n",
    "        # Normalize the readability score to 0-1 range\n",
    "        normalized_reading_ease = reading_ease / 100\n",
    "        readability_scores.append(normalized_reading_ease)\n",
    "\n",
    "    reading_ease_score_mean = np.mean(readability_scores)\n",
    "        \n",
    "    return reading_ease_score_mean\n",
    "\n",
    "def calculate_lexical_diversity(captions):\n",
    "    scores = []\n",
    "    for caption in captions:\n",
    "        tokens = caption.split()\n",
    "        num_tokens = len(tokens)\n",
    "        num_types = len(set(tokens))\n",
    "        ttr = num_types / num_tokens if num_tokens != 0 else 0\n",
    "        scores.append(ttr)\n",
    "    \n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Function to calculate overall quality score\n",
    "def calculate_overall_quality(readability, lexical_diversity, sentiment, weights=(0.4, 0.3, 0.3)):\n",
    "    readability_weight, lexical_diversity_weight, sentiment_weight = weights\n",
    "    overall_score = (\n",
    "        readability_weight * readability +\n",
    "        lexical_diversity_weight * lexical_diversity +\n",
    "        sentiment_weight * sentiment\n",
    "    )\n",
    "    return overall_score\n",
    "\n",
    "def get_overall_captions_quality(captions):\n",
    "    # Calculate overall quality scores for each caption\n",
    "    overall_quality_scores = calculate_overall_quality(calculate_readability_scores(captions), calculate_lexical_diversity(captions), calculate_sentiment(captions))\n",
    "\n",
    "    # Calculate the final overall quality score for the influencer\n",
    "    final_overall_quality_score = np.mean(overall_quality_scores)\n",
    "\n",
    "    return final_overall_quality_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "basic_features = []\n",
    "\n",
    "categories = [\n",
    "    'Automobile',\n",
    "    'Beverages',\n",
    "    'Clothing',\n",
    "    'Electronics',\n",
    "    'Entertainment',\n",
    "    'Food',\n",
    "    'Jewellery',\n",
    "    'Makeup',\n",
    "    'Non-profit',\n",
    "    'Shoes',\n",
    "]\n",
    "quadrant = [\n",
    "    'HF-HE',\n",
    "    'HF-LE',\n",
    "    'LF-HE',\n",
    "    'LF-LE',\n",
    "]\n",
    "for category in categories:\n",
    "    for quad in quadrant: \n",
    "\n",
    "        caption_folder_path = f'D://Study//Project//Major project//Bio analysis//{category}//{category}_{quad}_biography.xlsx'\n",
    "\n",
    "        df = pd.read_excel(caption_folder_path)\n",
    "\n",
    "        preprocessedCaptions = df['Captions'].apply(preprocess_text)\n",
    "\n",
    "        # COUNT NUMBER OF WORDS IN CAPTIONS\n",
    "        captionsWords = preprocessedCaptions.apply(countWords)\n",
    "\n",
    "        # COUNT NUMBER OF CHARACTERS IN CAPTIONS\n",
    "        captionsChars = preprocessedCaptions.apply(characterCount)\n",
    "\n",
    "        # COUNT NUMBER OF SENTENCES IN CAPTIONS\n",
    "        sentCount =  df['Captions'].apply(sentenceCount)\n",
    "\n",
    "        # COUNT AVERAGE WORD LENGTHS\n",
    "        averageWordLen = preprocessedCaptions.apply(calculateAvgWordLen)\n",
    "\n",
    "        # COUNT AVERAGE SENTENCE LENGTH --> NUMBER OF WORD PER SENTENCE\n",
    "        averageSentLen = df['Captions'].apply(calculateAvgSentLen)\n",
    "\n",
    "        # EXTRACT THE POS TAGS\n",
    "        pos_tags = df['Captions'].apply(extract_pos_tags)\n",
    "\n",
    "        # EXTRACT NAME-ENTITY\n",
    "        named_entity_tags = preprocessedCaptions.apply(extract_named_entity)\n",
    "\n",
    "        top_50_cap_pos_tags = rearrangePosTags(pos_tags)\n",
    "        top_50_cap_named_entity_tags = rearrangeNamedEntityTags(named_entity_tags)\n",
    "\n",
    "        subjectivity_score = df['Captions'].apply(calculate_subjectivity)\n",
    "\n",
    "        avgCapWords = captionsWords.mean()\n",
    "        avgCapChar = captionsChars.mean()\n",
    "        avgCapSentCount = sentCount.mean()\n",
    "        avgCapAvgWordLen = averageWordLen.mean()\n",
    "        avgCapAvgSentLen = averageSentLen.mean()\n",
    "        avgCapSubjScore = subjectivity_score.mean()\n",
    "\n",
    "        read_ease_score = calculate_readability_scores(list(df['Captions']))\n",
    "        lexical_diversity_score = calculate_lexical_diversity(list(df['Captions']))\n",
    "        sentiment_score = calculate_sentiment(list(df['Captions']))\n",
    "        overall_score = get_overall_captions_quality(list(df['Captions']))\n",
    "\n",
    "        curr = {\n",
    "            'Quadrant': quad,\n",
    "            'Category': category,\n",
    "            'read_ease_score': read_ease_score,\n",
    "            'lexical_diversity_score': lexical_diversity_score,\n",
    "            'sentiment_score': sentiment_score,\n",
    "            'overall_caption_score': overall_score,\n",
    "            'Average Words': avgCapWords,\n",
    "            'Average Characters': avgCapChar,\n",
    "            'Average Sentence Count': avgCapSentCount,\n",
    "            'Average Word Length': avgCapAvgWordLen,\n",
    "            'Average Sentence Length': avgCapAvgSentLen,\n",
    "            'Top 50 Captions Pos Tags': top_50_cap_pos_tags,\n",
    "            'Top 50 Captions Named Entity Tags': top_50_cap_named_entity_tags,\n",
    "            'Average Subjectivity Score': avgCapSubjScore\n",
    "        }\n",
    "\n",
    "        basic_features.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>Category</th>\n",
       "      <th>read_ease_score</th>\n",
       "      <th>lexical_diversity_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>overall_caption_score</th>\n",
       "      <th>Average Words</th>\n",
       "      <th>Average Characters</th>\n",
       "      <th>Average Sentence Count</th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Top 50 Captions Pos Tags</th>\n",
       "      <th>Top 50 Captions Named Entity Tags</th>\n",
       "      <th>Average Subjectivity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HF-HE</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>0.417992</td>\n",
       "      <td>0.926766</td>\n",
       "      <td>0.620637</td>\n",
       "      <td>0.631418</td>\n",
       "      <td>41.425287</td>\n",
       "      <td>251.816092</td>\n",
       "      <td>3.735632</td>\n",
       "      <td>6.130350</td>\n",
       "      <td>12.017226</td>\n",
       "      <td>{'VERB': 400, 'ADP': 394, 'DET': 299, 'PROPN':...</td>\n",
       "      <td>{'ORDINAL': 9, 'FAC': 4, 'GPE': 16, 'PERSON': ...</td>\n",
       "      <td>0.461825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HF-LE</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.905451</td>\n",
       "      <td>0.609179</td>\n",
       "      <td>0.629597</td>\n",
       "      <td>45.982544</td>\n",
       "      <td>283.620116</td>\n",
       "      <td>4.154613</td>\n",
       "      <td>6.371646</td>\n",
       "      <td>11.382521</td>\n",
       "      <td>{'NOUN': 15045, 'PART': 1114, 'VERB': 6327, 'A...</td>\n",
       "      <td>{'NORP': 130, 'DATE': 508, 'PERSON': 645, 'ORG...</td>\n",
       "      <td>0.424520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LF-HE</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>0.407392</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.633110</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>43.768031</td>\n",
       "      <td>269.629630</td>\n",
       "      <td>4.364522</td>\n",
       "      <td>6.603392</td>\n",
       "      <td>9.952685</td>\n",
       "      <td>{'PROPN': 4464, 'VERB': 2605, 'PRON': 1565, 'A...</td>\n",
       "      <td>{'GPE': 164, 'DATE': 209, 'TIME': 34, 'ORG': 1...</td>\n",
       "      <td>0.469017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LF-LE</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>0.317371</td>\n",
       "      <td>0.912266</td>\n",
       "      <td>0.659237</td>\n",
       "      <td>0.598399</td>\n",
       "      <td>53.914286</td>\n",
       "      <td>374.057143</td>\n",
       "      <td>4.457143</td>\n",
       "      <td>6.969275</td>\n",
       "      <td>12.295179</td>\n",
       "      <td>{'VERB': 251, 'ADP': 205, 'NOUN': 551, 'PUNCT'...</td>\n",
       "      <td>{'LOC': 3, 'ORG': 20, 'DATE': 15, 'PERSON': 25...</td>\n",
       "      <td>0.462154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HF-HE</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>0.508740</td>\n",
       "      <td>0.888757</td>\n",
       "      <td>0.626011</td>\n",
       "      <td>0.657926</td>\n",
       "      <td>43.780000</td>\n",
       "      <td>250.050000</td>\n",
       "      <td>4.335000</td>\n",
       "      <td>6.011502</td>\n",
       "      <td>10.600008</td>\n",
       "      <td>{'PRON': 658, 'ADJ': 602, 'NOUN': 2315, 'PUNCT...</td>\n",
       "      <td>{'CARDINAL': 25, 'ORG': 92, 'TIME': 10, 'DATE'...</td>\n",
       "      <td>0.480132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quadrant    Category  read_ease_score  lexical_diversity_score  \\\n",
       "0    HF-HE  Automobile         0.417992                 0.926766   \n",
       "1    HF-LE  Automobile         0.438019                 0.905451   \n",
       "2    LF-HE  Automobile         0.407392                 0.903653   \n",
       "3    LF-LE  Automobile         0.317371                 0.912266   \n",
       "4    HF-HE   Beverages         0.508740                 0.888757   \n",
       "\n",
       "   sentiment_score  overall_caption_score  Average Words  Average Characters  \\\n",
       "0         0.620637               0.631418      41.425287          251.816092   \n",
       "1         0.609179               0.629597      45.982544          283.620116   \n",
       "2         0.633110               0.623986      43.768031          269.629630   \n",
       "3         0.659237               0.598399      53.914286          374.057143   \n",
       "4         0.626011               0.657926      43.780000          250.050000   \n",
       "\n",
       "   Average Sentence Count  Average Word Length  Average Sentence Length  \\\n",
       "0                3.735632             6.130350                12.017226   \n",
       "1                4.154613             6.371646                11.382521   \n",
       "2                4.364522             6.603392                 9.952685   \n",
       "3                4.457143             6.969275                12.295179   \n",
       "4                4.335000             6.011502                10.600008   \n",
       "\n",
       "                            Top 50 Captions Pos Tags  \\\n",
       "0  {'VERB': 400, 'ADP': 394, 'DET': 299, 'PROPN':...   \n",
       "1  {'NOUN': 15045, 'PART': 1114, 'VERB': 6327, 'A...   \n",
       "2  {'PROPN': 4464, 'VERB': 2605, 'PRON': 1565, 'A...   \n",
       "3  {'VERB': 251, 'ADP': 205, 'NOUN': 551, 'PUNCT'...   \n",
       "4  {'PRON': 658, 'ADJ': 602, 'NOUN': 2315, 'PUNCT...   \n",
       "\n",
       "                   Top 50 Captions Named Entity Tags  \\\n",
       "0  {'ORDINAL': 9, 'FAC': 4, 'GPE': 16, 'PERSON': ...   \n",
       "1  {'NORP': 130, 'DATE': 508, 'PERSON': 645, 'ORG...   \n",
       "2  {'GPE': 164, 'DATE': 209, 'TIME': 34, 'ORG': 1...   \n",
       "3  {'LOC': 3, 'ORG': 20, 'DATE': 15, 'PERSON': 25...   \n",
       "4  {'CARDINAL': 25, 'ORG': 92, 'TIME': 10, 'DATE'...   \n",
       "\n",
       "   Average Subjectivity Score  \n",
       "0                    0.461825  \n",
       "1                    0.424520  \n",
       "2                    0.469017  \n",
       "3                    0.462154  \n",
       "4                    0.480132  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_quality_score_df2 = pd.DataFrame(basic_features)\n",
    "caption_quality_score_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_quality_score_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_quality_score_df2.to_excel(f'D://Study//Project//Major project//Bio analysis//biography_tect_analysis.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
